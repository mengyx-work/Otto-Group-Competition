{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61878, 95)\n",
      "Training set has 61878 rows and 95 columns\n",
      "RFC LogLoss 0.952919762767\n",
      "LogisticRegression LogLoss 0.672480385582\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import os\n",
    "\n",
    "os.system(\"ls ./\")\n",
    "\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "print train.shape\n",
    "print(\"Training set has {0[0]} rows and {0[1]} columns\".format(train.shape))\n",
    "\n",
    "labels = train['target']\n",
    "train.drop(['target', 'id'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#print(\"head result: \"+str(train.head()))\n",
    "\n",
    "### we need a test set that we didn't train on to find the best weights for combining the classifiers\n",
    "sss = StratifiedShuffleSplit(labels, test_size=0.05, random_state=1234)\n",
    "for train_index, test_index in sss:\n",
    "    break\n",
    "\n",
    "train_x, train_y = train.values[train_index], labels.values[train_index]\n",
    "test_x, test_y = train.values[test_index], labels.values[test_index]\n",
    "\n",
    "\n",
    "### building the classifiers\n",
    "clfs = []\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=20, random_state=4141, n_jobs=-1)\n",
    "rfc.fit(train_x, train_y)\n",
    "print('RFC LogLoss {score}'.format(score=log_loss(test_y, rfc.predict_proba(test_x))))\n",
    "clfs.append(rfc)\n",
    "\n",
    "### usually you'd use xgboost and neural nets here\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_x, train_y)\n",
    "print('LogisticRegression LogLoss {score}'.format(score=log_loss(test_y, logreg.predict_proba(test_x))))\n",
    "clfs.append(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predictions size:  1\n",
      "first row size:  3094\n",
      "element type:  <type 'numpy.ndarray'>\n",
      "the predictions size:  2\n",
      "first row size:  3094\n",
      "element type:  <type 'numpy.ndarray'>\n",
      "full shape:  (2, 3094, 9)\n",
      "0.5 (3094, 9)\n",
      "0.5 (3094, 9)\n",
      "0.5 (3094, 9)\n",
      "0.5 (3094, 9)\n",
      "0.500000014901 (3094, 9)\n",
      "0.5 (3094, 9)\n",
      "0.5 (3094, 9)\n",
      "0.500000014901 (3094, 9)\n",
      "0.524485822767 (3094, 9)\n",
      "0.475514177233 (3094, 9)\n",
      "0.524485822767 (3094, 9)\n",
      "0.475514177233 (3094, 9)\n",
      "0.524485837668 (3094, 9)\n",
      "0.475514177233 (3094, 9)\n",
      "0.524485822767 (3094, 9)\n",
      "0.475514192134 (3094, 9)\n",
      "0.630896281451 (3094, 9)\n",
      "0.369103718549 (3094, 9)\n",
      "0.630896281451 (3094, 9)\n",
      "0.369103718549 (3094, 9)\n",
      "0.630896296352 (3094, 9)\n",
      "0.369103718549 (3094, 9)\n",
      "0.630896281451 (3094, 9)\n",
      "0.36910373345 (3094, 9)\n",
      "0.681274946234 (3094, 9)\n",
      "0.318725053766 (3094, 9)\n",
      "0.681274946234 (3094, 9)\n",
      "0.318725053766 (3094, 9)\n",
      "0.681274961135 (3094, 9)\n",
      "0.318725053766 (3094, 9)\n",
      "0.681274946234 (3094, 9)\n",
      "0.318725068667 (3094, 9)\n",
      "0.676185558958 (3094, 9)\n",
      "0.323814441042 (3094, 9)\n",
      "0.676185558958 (3094, 9)\n",
      "0.323814441042 (3094, 9)\n",
      "0.67618557386 (3094, 9)\n",
      "0.323814441042 (3094, 9)\n",
      "0.676185558958 (3094, 9)\n",
      "0.323814455943 (3094, 9)\n",
      "Ensamble Score: 0.590997833565\n",
      "Best Weights: [ 0.67618556  0.32381444]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### finding the optimum weights\n",
    "\n",
    "predictions = []\n",
    "for clf in clfs:\n",
    "    predictions.append(clf.predict_proba(test_x))\n",
    "    print 'the predictions size: ', len(predictions)\n",
    "    print 'first row size: ', len(predictions[0])\n",
    "    print 'element type: ', type(predictions[0])\n",
    "\n",
    "temp = np.asarray(predictions)\n",
    "print 'full shape: ', temp.shape\n",
    "\n",
    "def log_loss_func(weights):\n",
    "    ''' scipy minimize will pass the weights as a numpy array '''\n",
    "    final_prediction = 0\n",
    "    #print 'the weights: ', weights\n",
    "    for weight, prediction in zip(weights, predictions):\n",
    "        print weight, prediction.shape\n",
    "        #print len(prediction)\n",
    "        final_prediction += weight*prediction\n",
    "        #print final_prediction.shape\n",
    "    return log_loss(test_y, final_prediction)\n",
    "\n",
    "#the algorithms need a starting value, right not we chose 0.5 for all weights\n",
    "#its better to choose many random starting points and run minimize a few times\n",
    "starting_values = [0.5]*len(predictions)\n",
    "#print starting_values\n",
    "#adding constraints  and a different solver as suggested by user 16universe\n",
    "#https://kaggle2.blob.core.windows.net/forum-message-attachments/75655/2393/otto%20model%20weights.pdf?sv=2012-02-12&se=2015-05-03T21%3A22%3A17Z&sr=b&sp=r&sig=rkeA7EJC%2BiQ%2FJ%2BcMpcA4lYQLFh6ubNqs2XAkGtFsAv0%3D\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "#our weights are bound between 0 and 1\n",
    "bounds = [(0,1)]*len(predictions)\n",
    "#print type(starting_values)\n",
    "res = minimize(log_loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "\n",
    "print('Ensamble Score: {best_score}'.format(best_score=res['fun']))\n",
    "print('Best Weights: {weights}'.format(weights=res['x']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
